# SSE Client Configuration Example
# Copy this file to config.yaml and fill in your API keys

providers:
  bailian:
    base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
    api_key: "your-bailian-api-key-here"
    models:
      - "qwen-max"
      - "qwen-plus"
      - "qwen-turbo"
      - "qwen-long"
      - "qwen2.5-72b-instruct"
      - "qwen2.5-32b-instruct"
      - "qwen2.5-14b-instruct"
      - "qwen2.5-7b-instruct"
      - "qwen2.5-3b-instruct"
      - "qwen2.5-1.5b-instruct"
      - "qwen2.5-0.5b-instruct"
      - "qwen2.5-coder-32b-instruct"
      - "qwen2.5-coder-14b-instruct"
      - "qwen2.5-coder-7b-instruct"
      - "qwen2.5-coder-3b-instruct"
      - "qwen2.5-coder-1.5b-instruct"
      - "qwen2.5-math-72b-instruct"
      - "qwen2.5-math-32b-instruct"
      - "qwen2.5-math-14b-instruct"
      - "qwen2.5-math-7b-instruct"
      - "qwen2-vl-72b-instruct"
      - "qwen2-vl-7b-instruct"
      - "qwen-vl-max"
      - "qwen-vl-plus"

  openai:
    base_url: "https://api.openai.com/v1/chat/completions"
    api_key: "your-openai-api-key-here"
    models:
      - "gpt-5-turbo"
      - "gpt-4o"
      - "gpt-4o-mini"
      - "gpt-4-turbo"
      - "gpt-4"
      - "gpt-3.5-turbo"
      - "gpt-3.5-turbo-16k"
      - "o1-preview"
      - "o1-mini"

  google:
    base_url: "https://generativelanguage.googleapis.com/v1beta/models"
    api_key: "your-google-api-key-here"
    models:
      - "gemini-2.5-pro"
      - "gemini-2.5-flash"
      - "gemini-2.0-flash-exp"
      - "gemini-1.5-pro"
      - "gemini-1.5-flash"
      - "gemini-1.0-pro"

  anthropic:
    base_url: "https://api.anthropic.com/v1/messages"
    api_key: "your-anthropic-api-key-here"
    models:
      - "claude-4-opus-20250514"
      - "claude-4-sonnet-20250514"
      - "claude-4-haiku-20250514"
      - "claude-3-5-sonnet-20241022"
      - "claude-3-5-haiku-20241022"
      - "claude-3-opus-20240229"

  deepseek:
    base_url: "https://api.deepseek.com/v1"
    api_key: "your-deepseek-api-key-here"
    models:
      - "deepseek-chat"
      - "deepseek-coder"
      - "deepseek-reasoner"

# Global settings
timeout: 60
max_tokens: 4096
temperature: 0.7